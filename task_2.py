# -*- coding: utf-8 -*-
"""Task-2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ck_x8zdLJT7oYR8wBi3CEWoqixEo7y3B
"""

# Task 2: Deep Learning Model for Default Prediction

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import roc_auc_score, f1_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt

data = np.load('processed_data.npz', allow_pickle=True)
X_train, X_test = data['X_train'], data['X_test']
y_train, y_test = data['y_train'], data['y_test']
feature_names = data['feature_names']

print("="*60)
print("TASK 2: SUPERVISED DEEP LEARNING MODEL")
print("="*60)
print(f"\nData loaded:")
print(f"  Train: {X_train.shape[0]:,} samples, {X_train.shape[1]} features")
print(f"  Test:  {X_test.shape[0]:,} samples")
print(f"  Default rate: {y_train.mean():.2%}\n")

class LoanDataset(Dataset):
    def __init__(self, X, y):
        self.X = torch.FloatTensor(X)
        self.y = torch.FloatTensor(y)

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

train_dataset = LoanDataset(X_train, y_train)
test_dataset = LoanDataset(X_test, y_test)

train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)

class DefaultPredictor(nn.Module):
    def __init__(self, input_dim):
        super().__init__()
        self.network = nn.Sequential(
            nn.Linear(input_dim, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(0.3),

            nn.Linear(256, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(0.3),

            nn.Linear(128, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Dropout(0.2),

            nn.Linear(64, 32),
            nn.ReLU(),

            nn.Linear(32, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        return self.network(x).squeeze()

model = DefaultPredictor(input_dim=X_train.shape[1])
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)

print(f"Model architecture:")
print(f"  Input: {X_train.shape[1]} features")
print(f"  Hidden layers: 256 → 128 → 64 → 32")
print(f"  Output: 1 (probability)")
print(f"  Device: {device}\n")

# 1. TRAINING

criterion = nn.BCELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5)

def train_epoch(model, loader, criterion, optimizer):
    model.train()
    total_loss = 0
    correct = 0
    total = 0

    for X_batch, y_batch in loader:
        X_batch, y_batch = X_batch.to(device), y_batch.to(device)

        optimizer.zero_grad()
        outputs = model(X_batch)
        loss = criterion(outputs, y_batch)
        loss.backward()
        optimizer.step()

        total_loss += loss.item()
        predictions = (outputs > 0.5).float()
        correct += (predictions == y_batch).sum().item()
        total += y_batch.size(0)

    return total_loss / len(loader), correct / total

def evaluate(model, loader):
    model.eval()
    total_loss = 0
    correct = 0
    total = 0

    with torch.no_grad():
        for X_batch, y_batch in loader:
            X_batch, y_batch = X_batch.to(device), y_batch.to(device)
            outputs = model(X_batch)
            loss = criterion(outputs, y_batch)

            total_loss += loss.item()
            predictions = (outputs > 0.5).float()
            correct += (predictions == y_batch).sum().item()
            total += y_batch.size(0)

    return total_loss / len(loader), correct / total

print("Training model...")
print("-" * 60)

history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}
epochs = 30
best_val_loss = float('inf')

for epoch in range(epochs):
    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)
    val_loss, val_acc = evaluate(model, test_loader)

    scheduler.step(val_loss)

    history['train_loss'].append(train_loss)
    history['val_loss'].append(val_loss)
    history['train_acc'].append(train_acc)
    history['val_acc'].append(val_acc)

    if val_loss < best_val_loss:
        best_val_loss = val_loss
        torch.save(model.state_dict(), 'best_model.pth')

    if (epoch + 1) % 5 == 0:
        print(f"Epoch {epoch+1:2d}/{epochs} | "
              f"Loss: {train_loss:.4f}/{val_loss:.4f} | "
              f"Acc: {train_acc:.4f}/{val_acc:.4f}")

print("\n✓ Training complete!")

# 2. EVALUATION
model.load_state_dict(torch.load('best_model.pth'))
model.eval()

# Get predictions
y_pred_proba = []
y_pred = []

with torch.no_grad():
    for X_batch, _ in test_loader:
        X_batch = X_batch.to(device)
        outputs = model(X_batch)
        y_pred_proba.extend(outputs.cpu().numpy())
        predictions = (outputs > 0.5).float()
        y_pred.extend(predictions.cpu().numpy())

y_pred = np.array(y_pred)
y_pred_proba = np.array(y_pred_proba)

# Calculate metrics
auc = roc_auc_score(y_test, y_pred_proba)
f1 = f1_score(y_test, y_pred)

print("\n" + "="*60)
print("EVALUATION RESULTS")
print("="*60)
print(f"\n✓ ROC-AUC Score: {auc:.4f}")
print(f"✓ F1-Score:      {f1:.4f}\n")

print("Classification Report:")
print("-" * 60)
print(classification_report(y_test, y_pred, target_names=['Paid', 'Default']))

print("Confusion Matrix:")
print("-" * 60)
cm = confusion_matrix(y_test, y_pred)
print(f"                Predicted")
print(f"                Paid    Default")
print(f"Actual  Paid    {cm[0,0]:<8,} {cm[0,1]:<8,}")
print(f"        Default {cm[1,0]:<8,} {cm[1,1]:<8,}")

# Calculate additional metrics
tn, fp, fn, tp = cm.ravel()
specificity = tn / (tn + fp)
sensitivity = tp / (tp + fn)
print(f"\nAdditional Metrics:")
print(f"  Sensitivity (Recall): {sensitivity:.4f}")
print(f"  Specificity:          {specificity:.4f}")

fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# Training history
ax1 = axes[0, 0]
ax1.plot(history['train_loss'], label='Train Loss', linewidth=2)
ax1.plot(history['val_loss'], label='Val Loss', linewidth=2)
ax1.set_xlabel('Epoch')
ax1.set_ylabel('Loss')
ax1.set_title('Training and Validation Loss')
ax1.legend()
ax1.grid(alpha=0.3)

ax2 = axes[0, 1]
ax2.plot(history['train_acc'], label='Train Acc', linewidth=2)
ax2.plot(history['val_acc'], label='Val Acc', linewidth=2)
ax2.set_xlabel('Epoch')
ax2.set_ylabel('Accuracy')
ax2.set_title('Training and Validation Accuracy')
ax2.legend()
ax2.grid(alpha=0.3)

# ROC Curve
from sklearn.metrics import roc_curve
ax3 = axes[1, 0]
fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
ax3.plot(fpr, tpr, linewidth=2, label=f'ROC (AUC = {auc:.3f})')
ax3.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random')
ax3.set_xlabel('False Positive Rate')
ax3.set_ylabel('True Positive Rate')
ax3.set_title('ROC Curve')
ax3.legend()
ax3.grid(alpha=0.3)

# Prediction distribution
ax4 = axes[1, 1]
ax4.hist(y_pred_proba[y_test == 0], bins=50, alpha=0.6, label='Paid', color='green')
ax4.hist(y_pred_proba[y_test == 1], bins=50, alpha=0.6, label='Default', color='red')
ax4.axvline(0.5, color='black', linestyle='--', linewidth=2, label='Threshold')
ax4.set_xlabel('Predicted Probability')
ax4.set_ylabel('Frequency')
ax4.set_title('Prediction Distribution')
ax4.legend()
ax4.grid(alpha=0.3)

plt.tight_layout()
plt.savefig('task2_results.png', dpi=300)
print("\n✓ Visualizations saved to 'task2_results.png'")


# Save predictions for Task 3
np.savez('task2_predictions.npz',
         y_test=y_test,
         y_pred=y_pred,
         y_pred_proba=y_pred_proba,
         auc=auc,
         f1=f1)

print("✓ Predictions saved to 'task2_predictions.npz'")

print("\n" + "="*60)
print("TASK 2 COMPLETE")
print("="*60)
print(f"\nKey Results:")
print(f"  • ROC-AUC: {auc:.4f}")
print(f"  • F1-Score: {f1:.4f}")
print(f"  • Accuracy: {history['val_acc'][-1]:.4f}")
print(f"\nReady for Task 3 (Offline RL)!")