# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ck_x8zdLJT7oYR8wBi3CEWoqixEo7y3B
"""

# Task 1: EDA and Preprocessing - LendingClub Loan Data
# Concise, production-ready implementation

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler

# 1. LOAD DATA

df = pd.read_csv('accepted_2007_to_2018.csv', low_memory=False)
print(f"Dataset: {df.shape[0]:,} rows × {df.shape[1]} columns\n")

bad_statuses = ['Charged Off', 'Default', 'Late (31-120 days)',
                'Late (16-30 days)', 'Does not meet the credit policy. Status:Charged Off']
df['default'] = df['loan_status'].isin(bad_statuses).astype(int)

print(f"Default Rate: {df['default'].mean():.2%}")
print(f"Defaults: {df['default'].sum():,} | Non-defaults: {(~df['default'].astype(bool)).sum():,}\n")

# 3. FEATURE SELECTION
features = [

    'loan_amnt', 'term', 'int_rate', 'installment', 'grade', 'emp_length',
    'home_ownership', 'annual_inc', 'verification_status', 'purpose', 'dti',
    'delinq_2yrs', 'fico_range_low', 'fico_range_high', 'inq_last_6mths',
    'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc'
]

# Keep only features with <50% missing
available = [f for f in features if f in df.columns and df[f].isnull().mean() < 0.5]
df = df[available + ['default']].copy()

print(f"Selected {len(available)} features with <50% missing values\n")

# QUICK EDA
print("KEY INSIGHTS:")
print("-" * 50)

if 'grade' in df.columns:
    grade_default = df.groupby('grade')['default'].mean()
    print("\nDefault Rate by Grade:")
    for grade, rate in grade_default.items():
        print(f"  {grade}: {rate:.1%}")

# Key stats
numerical = ['loan_amnt', 'int_rate', 'annual_inc', 'dti', 'fico_range_low']
for col in numerical:
    if col in df.columns:
        defaulted = df[df['default']==1][col].mean()
        paid = df[df['default']==0][col].mean()
        diff = (defaulted - paid) / paid * 100
        print(f"\n{col}: Defaulted avg = {defaulted:.0f}, Paid avg = {paid:.0f} ({diff:+.1f}%)")


# 5. FEATURE ENGINEERING
print("\n\nFEATURE ENGINEERING:")
print("-" * 50)

if 'term' in df.columns:
    df['term_months'] = df['term'].str.extract('(\d+)').astype(float)

if 'emp_length' in df.columns:
    emp_map = {'< 1 year': 0, '1 year': 1, '2 years': 2, '3 years': 3, '4 years': 4,
               '5 years': 5, '6 years': 6, '7 years': 7, '8 years': 8, '9 years': 9,
               '10+ years': 10}
    df['emp_length_years'] = df['emp_length'].map(emp_map).fillna(0)

if 'grade' in df.columns:
    df['grade_num'] = df['grade'].map({'A':1,'B':2,'C':3,'D':4,'E':5,'F':6,'G':7})

if 'int_rate' in df.columns and df['int_rate'].dtype == 'object':
    df['int_rate'] = df['int_rate'].str.rstrip('%').astype(float)

if 'revol_util' in df.columns and df['revol_util'].dtype == 'object':
    df['revol_util'] = df['revol_util'].str.rstrip('%').astype(float)

# Derived features
if 'loan_amnt' in df.columns and 'annual_inc' in df.columns:
    df['loan_to_income'] = df['loan_amnt'] / (df['annual_inc'] + 1)

if 'fico_range_low' in df.columns and 'fico_range_high' in df.columns:
    df['fico_avg'] = (df['fico_range_low'] + df['fico_range_high']) / 2

# Risk flags
if 'delinq_2yrs' in df.columns:
    df['has_delinq'] = (df['delinq_2yrs'] > 0).astype(int)

if 'pub_rec' in df.columns:
    df['has_pub_rec'] = (df['pub_rec'] > 0).astype(int)

print("✓ Created derived features\n")

# MISSING VALS

numerical_cols = df.select_dtypes(include=[np.number]).columns
df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].median())

categorical_cols = df.select_dtypes(include=['object']).columns
for col in categorical_cols:
    df[col] = df[col].fillna(df[col].mode()[0] if len(df[col].mode()) > 0 else 'Unknown')

print("✓ Imputed missing values\n")

# One-hot encode
cat_to_encode = ['home_ownership', 'verification_status', 'purpose']
cat_to_encode = [c for c in cat_to_encode if c in df.columns]

df = pd.get_dummies(df, columns=cat_to_encode, drop_first=True)
print(f"✓ Encoded categorical variables\n")

# 8. FINAL DATASET
feature_cols = [c for c in df.columns if c not in ['default', 'term', 'grade', 'emp_length']]
feature_cols = [c for c in feature_cols if df[c].dtype in [np.int64, np.float64]]

X = df[feature_cols].values
y = df['default'].values

print(f"FINAL DATASET:")
print(f"  Samples: {X.shape[0]:,}")
print(f"  Features: {X.shape[1]}")
print(f"  Default rate: {y.mean():.2%}")
print(f"\nFeatures: {feature_cols[:10]}... (showing first 10)")

# 9. TRAIN-TEST SPLIT & SCALING
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

print(f"\n✓ Train: {X_train.shape[0]:,} | Test: {X_test.shape[0]:,}")
print("\n" + "="*50)
print("TASK 1 COMPLETE - Ready for modeling!")
print("="*50)

# Save for Task 2 & 3
np.savez('processed_data.npz',
         X_train=X_train, X_test=X_test,
         y_train=y_train, y_test=y_test,
         feature_names=feature_cols)

print("\n✓ Saved to 'processed_data.npz'")
fig, axes = plt.subplots(1, 3, figsize=(15, 4))

axes[0].bar(['Paid', 'Default'], [len(y)-y.sum(), y.sum()], color=['green','red'], alpha=0.7)
axes[0].set_title('Target Distribution')
axes[0].set_ylabel('Count')

if 'grade_num' in df.columns:
    grade_default = df.groupby('grade_num')['default'].mean() * 100
    axes[1].bar(range(len(grade_default)), grade_default.values, color='coral')
    axes[1].set_xticks(range(len(grade_default)))
    axes[1].set_xticklabels(['A','B','C','D','E','F','G'])
    axes[1].set_title('Default Rate by Grade')
    axes[1].set_ylabel('Default Rate (%)')

corr_with_target = df[feature_cols + ['default']].corr()['default'].drop('default').abs()
top_10 = corr_with_target.nlargest(10)
axes[2].barh(range(len(top_10)), top_10.values)
axes[2].set_yticks(range(len(top_10)))
axes[2].set_yticklabels(top_10.index)
axes[2].set_title('Top 10 Features by Correlation')
axes[2].set_xlabel('|Correlation|')

plt.tight_layout()
plt.savefig('task1_summary.png', dpi=300)
print("✓ Saved visualization to 'task1_summary.png'")